{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all vocabularies sorted from more frequent to less frequent:\n",
      " ['9' '3' 'o' '6' 'a' '1' 'i' 'g' 's' '4' 'l' 'k' '8' 'u' '2' 'd' '5' 'y'\n",
      " 'f' 'e' 'h' 'p' 'q' '0' 'j' '7' 't' 'r' 'w' 'n']\n",
      "5 example pairs:\n",
      " [[16 14 12  3  9]\n",
      " [14  9  3 14 12]\n",
      " [ 9 12 14  1  3]\n",
      " [12  3  1  3 14]\n",
      " [ 3 14  3  9  1]]\n",
      "WARNING:tensorflow:From D:\\IDE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'apply_gradients'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d42a5d65b78a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_w2v_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"cbow\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCBOW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-d42a5d65b78a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mbx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mbx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"step: {} | loss: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-d42a5d65b78a>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'apply_gradients'"
     ]
    }
   ],
   "source": [
    "# [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from utils import process_w2v_data\n",
    "from visual import show_w2v_word_embedding\n",
    "import keras.backend as K\n",
    "\n",
    "corpus = [\n",
    "    # numbers\n",
    "    \"5 2 4 8 6 2 3 6 4\",\n",
    "    \"4 8 5 6 9 5 5 6\",\n",
    "    \"1 1 5 2 3 3 8\",\n",
    "    \"3 6 9 6 8 7 4 6 3\",\n",
    "    \"8 9 9 6 1 4 3 4\",\n",
    "    \"1 0 2 0 2 1 3 3 3 3 3\",\n",
    "    \"9 3 3 0 1 4 7 8\",\n",
    "    \"9 9 8 5 6 7 1 2 3 0 1 0\",\n",
    "\n",
    "    # alphabets, expecting that 9 is close to letters\n",
    "    \"a t g q e h 9 u f\",\n",
    "    \"e q y u o i p s\",\n",
    "    \"q o 9 p l k j o k k o p\",\n",
    "    \"h g y i u t t a e q\",\n",
    "    \"i k d q r e 9 e a d\",\n",
    "    \"o p d g 9 s a f g a\",\n",
    "    \"i u y g h k l a s w\",\n",
    "    \"o l u y a o g f s\",\n",
    "    \"o p i u y g d a s j d l\",\n",
    "    \"u k i l o 9 l j s\",\n",
    "    \"y g i s h k j l f r f\",\n",
    "    \"i o h n 9 9 d 9 f a 9\",\n",
    "]\n",
    "\n",
    "\n",
    "class CBOW(keras.Model):\n",
    "    def __init__(self, v_dim, emb_dim):\n",
    "        super().__init__()\n",
    "        self.v_dim = v_dim\n",
    "        self.embeddings = keras.layers.Embedding(\n",
    "            input_dim=v_dim, output_dim=emb_dim,  # [n_vocab, emb_dim]\n",
    "            embeddings_initializer=keras.initializers.RandomNormal(0., 0.1),\n",
    "        )\n",
    "\n",
    "        # noise-contrastive estimation\n",
    "        self.nce_w = self.add_weight(\n",
    "            name=\"nce_w\", shape=[v_dim, emb_dim],\n",
    "            initializer=keras.initializers.TruncatedNormal(0., 0.1))  # [n_vocab, emb_dim]\n",
    "        self.nce_b = self.add_weight(\n",
    "            name=\"nce_b\", shape=(v_dim,),\n",
    "            initializer=keras.initializers.Constant(0.1))  # [n_vocab, ]\n",
    "\n",
    "        self.opt = keras.optimizers.Adam(0.01)\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        # x.shape = [n, skip_window*2]\n",
    "        o = self.embeddings(x)          # [n, skip_window*2, emb_dim]\n",
    "        o = tf.reduce_mean(o, axis=1)   # [n, emb_dim]\n",
    "        return o\n",
    "\n",
    "    # negative sampling: take one positive label and num_sampled negative labels to compute the loss\n",
    "    # in order to reduce the computation of full softmax\n",
    "    def loss(self, x, y, training=None):\n",
    "        embedded = self.call(x, training)\n",
    "        return tf.reduce_mean(\n",
    "            tf.nn.nce_loss(\n",
    "                weights=self.nce_w, biases=self.nce_b, labels=tf.expand_dims(y, axis=1),\n",
    "                inputs=embedded, num_sampled=5, num_classes=self.v_dim))\n",
    "\n",
    "    def step(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.loss(x, y, True)\n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        return loss.numpy()\n",
    "\n",
    "\n",
    "def train(model, data):\n",
    "    for t in range(2500):\n",
    "        bx, by = data.sample(8)\n",
    "        bx, by = K.constant(bx), K.constant(by)\n",
    "        loss = model.step(bx, by)\n",
    "        if t % 200 == 0:\n",
    "            print(\"step: {} | loss: {}\".format(t, loss))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    d = process_w2v_data(corpus, skip_window=2, method=\"cbow\")\n",
    "    m = CBOW(d.num_word, 2)\n",
    "    train(m, d)\n",
    "\n",
    "    # plotting\n",
    "    show_w2v_word_embedding(m, d, \"./visual/results/cbow.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
