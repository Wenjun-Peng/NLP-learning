{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prelearning for NLP\n",
    "* TF: term frequency, 某个词在某篇文章中出现的频率,用于衡量一篇文章中某个词的重要性</br>\n",
    "TF = 某篇文章中某词条出现的次数/该篇文章中所有词条数目\n",
    "* IDF: inverse document frequency, 全局中文章包含某个词的频率，用于衡量某一词在某一篇文章中的独特区分性（去除\"你，我，他\"之中在很多文章中都出现词的干扰）\n",
    "IDF = log(语料库中的文档总数/(包含某词条的文档数)+1)\n",
    "* TF-IDF：两者结合使用将该篇文章的关键字提取出来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算相关性\n",
    "* 使用TF与IDF计算出该文档中每个词的TF，IDF值\n",
    "* 将词对应的TF与IDF值相乘\n",
    "* 将这些值视作一个vector，如下图:</br>\n",
    "![avatar](pic/doc-vectors.png)\n",
    "* 搜索时，将关键词vector化，计算与各个文档vector的cos距离，进行相关性排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['it', 'is', 'a', 'good', 'day', 'I', 'like', 'to', 'stay', 'here'], ['I', 'am', 'happy', 'to', 'be', 'here'], ['I', 'am', 'bob'], ['it', 'is', 'sunny', 'today'], ['I', 'have', 'a', 'party', 'today'], ['it', 'is', 'a', 'dog', 'and', 'that', 'is', 'a', 'cat'], ['there', 'are', 'dog', 'and', 'cat', 'on', 'the', 'tree'], ['I', 'study', 'hard', 'this', 'morning'], ['today', 'is', 'a', 'good', 'day'], ['tomorrow', 'will', 'be', 'a', 'good', 'day'], ['I', 'like', 'coffee', 'I', 'like', 'book', 'and', 'I', 'like', 'apple'], ['I', 'do', 'not', 'like', 'it'], ['I', 'am', 'kitty', 'I', 'like', 'bob'], ['I', 'do', 'not', 'care', 'who', 'like', 'bob', 'but', 'I', 'like', 'kitty'], ['It', 'is', 'coffee', 'time', 'bring', 'your', 'cup']]\n",
      "{'am': 0, 'bob': 1, 'day': 2, 'happy': 3, 'tomorrow': 4, 'like': 5, 'a': 6, 'I': 7, 'coffee': 8, 'cat': 9, 'care': 10, 'but': 11, 'have': 12, 'this': 13, 'your': 14, 'today': 15, 'It': 16, 'will': 17, 'hard': 18, 'book': 19, 'there': 20, 'time': 21, 'bring': 22, 'are': 23, 'stay': 24, 'to': 25, 'sunny': 26, 'tree': 27, 'the': 28, 'cup': 29, 'who': 30, 'that': 31, 'and': 32, 'on': 33, 'kitty': 34, 'dog': 35, 'it': 36, 'be': 37, 'is': 38, 'not': 39, 'do': 40, 'morning': 41, 'here': 42, 'apple': 43, 'study': 44, 'party': 45, 'good': 46}\n",
      "{0: 'am', 1: 'bob', 2: 'day', 3: 'happy', 4: 'tomorrow', 5: 'like', 6: 'a', 7: 'I', 8: 'coffee', 9: 'cat', 10: 'care', 11: 'but', 12: 'have', 13: 'this', 14: 'your', 15: 'today', 16: 'It', 17: 'will', 18: 'hard', 19: 'book', 20: 'there', 21: 'time', 22: 'bring', 23: 'are', 24: 'stay', 25: 'to', 26: 'sunny', 27: 'tree', 28: 'the', 29: 'cup', 30: 'who', 31: 'that', 32: 'and', 33: 'on', 34: 'kitty', 35: 'dog', 36: 'it', 37: 'be', 38: 'is', 39: 'not', 40: 'do', 41: 'morning', 42: 'here', 43: 'apple', 44: 'study', 45: 'party', 46: 'good'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import itertools\n",
    "# from visual import show_tfidf\n",
    "\n",
    "docs = [\n",
    "    \"it is a good day, I like to stay here\",\n",
    "    \"I am happy to be here\",\n",
    "    \"I am bob\",\n",
    "    \"it is sunny today\",\n",
    "    \"I have a party today\",\n",
    "    \"it is a dog and that is a cat\",\n",
    "    \"there are dog and cat on the tree\",\n",
    "    \"I study hard this morning\",\n",
    "    \"today is a good day\",\n",
    "    \"tomorrow will be a good day\",\n",
    "    \"I like coffee, I like book and I like apple\",\n",
    "    \"I do not like it\",\n",
    "    \"I am kitty, I like bob\",\n",
    "    \"I do not care who like bob, but I like kitty\",\n",
    "    \"It is coffee time, bring your cup\",\n",
    "]\n",
    "\n",
    "docs_words = [d.replace(\",\", \"\").split(\" \") for d in docs]\n",
    "vocab = set(itertools.chain(*docs_words))\n",
    "v2i = {v: i for i, v in enumerate(vocab)}\n",
    "i2v = {i: v for v, i in v2i.items()}\n",
    "print(docs_words)\n",
    "print(v2i)\n",
    "print(i2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_log(x):\n",
    "    mask = x != 0\n",
    "    x[mask] = np.log(x[mask])\n",
    "    return x\n",
    "\n",
    "\n",
    "tf_methods = {\n",
    "        \"log\": lambda x: np.log(1+x),\n",
    "        \"augmented\": lambda x: 0.5 + 0.5 * x / np.max(x, axis=1, keepdims=True),\n",
    "        \"boolean\": lambda x: np.minimum(x, 1),\n",
    "        \"log_avg\": lambda x: (1 + safe_log(x)) / (1 + safe_log(np.mean(x, axis=1, keepdims=True))),\n",
    "    }\n",
    "idf_methods = {\n",
    "        \"log\": lambda x: 1 + np.log(len(docs) / (x+1)),\n",
    "        \"prob\": lambda x: np.maximum(0, np.log((len(docs) - x) / (x+1))),\n",
    "        \"len_norm\": lambda x: x / (np.sum(np.square(x))+1),\n",
    "    }\n",
    "\n",
    "def get_tf(method=\"log\"):\n",
    "    # term frequency: how frequent a word appears in a doc\n",
    "    _tf = np.zeros((len(vocab), len(docs)), dtype=np.float64)    # [n_vocab, n_doc]\n",
    "    for i, d in enumerate(docs_words):\n",
    "        counter = Counter(d)\n",
    "        for v in counter.keys():\n",
    "            _tf[v2i[v], i] = counter[v] / counter.most_common(1)[0][1]\n",
    "\n",
    "    weighted_tf = tf_methods.get(method, None)\n",
    "    if weighted_tf is None:\n",
    "        raise ValueError\n",
    "    return weighted_tf(_tf)\n",
    "\n",
    "\n",
    "def get_idf(method=\"log\"):\n",
    "    # inverse document frequency: low idf for a word appears in more docs, mean less important\n",
    "    df = np.zeros((len(i2v), 1))\n",
    "    for i in range(len(i2v)):\n",
    "        d_count = 0\n",
    "        for d in docs_words:\n",
    "            d_count += 1 if i2v[i] in d else 0\n",
    "        df[i, 0] = d_count\n",
    "\n",
    "    idf_fn = idf_methods.get(method, None)\n",
    "    if idf_fn is None:\n",
    "        raise ValueError\n",
    "    return idf_fn(df)\n",
    "\n",
    "\n",
    "def cosine_similarity(q, _tf_idf):\n",
    "    unit_q = q / np.sqrt(np.sum(np.square(q), axis=0, keepdims=True))\n",
    "    unit_ds = _tf_idf / np.sqrt(np.sum(np.square(_tf_idf), axis=0, keepdims=True))\n",
    "    similarity = unit_ds.T.dot(unit_q).ravel()\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def docs_score(q, len_norm=False):\n",
    "    q_words = q.replace(\",\", \"\").split(\" \")\n",
    "\n",
    "    # add unknown words\n",
    "    unknown_v = 0\n",
    "    for v in set(q_words):\n",
    "        if v not in v2i:\n",
    "            v2i[v] = len(v2i)\n",
    "            i2v[len(v2i)-1] = v\n",
    "            unknown_v += 1\n",
    "    if unknown_v > 0:\n",
    "        _idf = np.concatenate((idf, np.zeros((unknown_v, 1), dtype=np.float)), axis=0)\n",
    "        _tf_idf = np.concatenate((tf_idf, np.zeros((unknown_v, tf_idf.shape[1]), dtype=np.float)), axis=0)\n",
    "    else:\n",
    "        _idf, _tf_idf = idf, tf_idf\n",
    "    counter = Counter(q_words)\n",
    "    q_tf = np.zeros((len(_idf), 1), dtype=np.float)     # [n_vocab, 1]\n",
    "    for v in counter.keys():\n",
    "        q_tf[v2i[v], 0] = counter[v]\n",
    "\n",
    "    q_vec = q_tf * _idf            # [n_vocab, 1]\n",
    "\n",
    "    q_scores = cosine_similarity(q_vec, _tf_idf)\n",
    "    if len_norm:\n",
    "        len_docs = [len(d) for d in docs_words]\n",
    "        q_scores = q_scores / np.array(len_docs)\n",
    "    return q_scores\n",
    "\n",
    "\n",
    "def get_keywords(n=2):\n",
    "    for c in range(3):\n",
    "        col = tf_idf[:, c]\n",
    "        idx = np.argsort(col)[-n:]\n",
    "        print(\"doc{}, top{} keywords {}\".format(c, n, [i2v[i] for i in idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf shape(vecb in each docs):  (47, 15)\n",
      "\n",
      "tf samples:\n",
      " [[0.         0.69314718 0.69314718 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.40546511 0.         0.        ]\n",
      " [0.         0.         0.69314718 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.40546511 0.40546511 0.        ]]\n",
      "\n",
      "idf shape(vecb in all docs):  (47, 1)\n",
      "\n",
      "idf samples:\n",
      " [[2.32175584]\n",
      " [2.32175584]]\n",
      "\n",
      "tf_idf shape:  (47, 15)\n",
      "\n",
      "tf_idf sample:\n",
      " [[0.         1.60931851 1.60931851 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.94139098 0.         0.        ]\n",
      " [0.         0.         1.60931851 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.94139098 0.94139098 0.        ]]\n",
      "doc0, top2 keywords ['here', 'stay']\n",
      "doc1, top2 keywords ['here', 'happy']\n",
      "doc2, top2 keywords ['bob', 'am']\n",
      "\n",
      "top 3 docs for 'I get a coffee cup':\n",
      "['It is coffee time, bring your cup', 'I like coffee, I like book and I like apple', 'I have a party today']\n"
     ]
    }
   ],
   "source": [
    "tf = get_tf()           # [n_vocab, n_doc]\n",
    "idf = get_idf()         # [n_vocab, 1]\n",
    "tf_idf = tf * idf       # [n_vocab, n_doc]\n",
    "print(\"tf shape(vecb in each docs): \", tf.shape)\n",
    "print(\"\\ntf samples:\\n\", tf[:2])\n",
    "print(\"\\nidf shape(vecb in all docs): \", idf.shape)\n",
    "print(\"\\nidf samples:\\n\", idf[:2])\n",
    "print(\"\\ntf_idf shape: \", tf_idf.shape)\n",
    "print(\"\\ntf_idf sample:\\n\", tf_idf[:2])\n",
    "\n",
    "\n",
    "# test\n",
    "get_keywords()\n",
    "q = \"I get a coffee cup\"\n",
    "scores = docs_score(q)\n",
    "d_ids = scores.argsort()[-3:][::-1]\n",
    "print(\"\\ntop 3 docs for '{}':\\n{}\".format(q, [docs[i] for i in d_ids]))\n",
    "\n",
    "# show_tfidf(tf_idf.T, [i2v[i] for i in range(len(i2v))], \"tfidf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
